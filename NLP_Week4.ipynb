{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFZ7AjFDlxQb"
      },
      "source": [
        "# Backend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qlUuLsiIiH7z"
      },
      "outputs": [],
      "source": [
        "import nltk.corpus\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLX41d_WIWTc",
        "outputId": "22f27b8e-6d87-4043-8a76-ab821a26dd96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to\n",
            "[nltk_data]     C:\\Users\\DAVA\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('brown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "prc-9nVSmO_p"
      },
      "outputs": [],
      "source": [
        "sentences = nltk.corpus.brown.sents(categories='fiction')\n",
        "n_grams = defaultdict(list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "collections.defaultdict"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(n_grams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3nOl6mjo4m-",
        "outputId": "113742cf-5e23-410e-e508-8d081225dfa2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nltk.corpus.reader.util.ConcatenatedCorpusView"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IyzXcn_WmNLn"
      },
      "outputs": [],
      "source": [
        "for sentence in sentences:\n",
        "    words = [word.lower() for word in sentence if word[0].isalpha()]\n",
        "    for ix in range(2, len(words) - 1):  # Perbaikan indeks\n",
        "        current_word = words[ix]\n",
        "        previous_word1 = words[ix - 1]\n",
        "        next_word = words[ix + 1]  # Mengambil kata yang mengikuti tri-gram\n",
        "        tri_gram = (previous_word1, current_word)\n",
        "        n_grams[tri_gram].append(next_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lfu4LNyiN5Qe"
      },
      "outputs": [],
      "source": [
        "for sentence in sentences:\n",
        "    words = [word.lower() for word in sentence if word[0].isalpha()]\n",
        "    for ix in range(2, len(words) - 2):  \n",
        "        current_word = words[ix]\n",
        "        previous_word1 = words[ix - 1]\n",
        "        previous_word2 = words[ix - 2]\n",
        "        next_word = words[ix + 1]\n",
        "        next_word2 = words[ix + 2] \n",
        "        tri_gram = (previous_word2, previous_word1, current_word)\n",
        "        n_grams[tri_gram].append((next_word, next_word2)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oGFFNd0QN4oF"
      },
      "outputs": [],
      "source": [
        "ngram_probabilities = {}\n",
        "\n",
        "for current_word, next_words in n_grams.items():\n",
        "    word_probabilities = {}\n",
        "    word_count = len(next_words)\n",
        "\n",
        "    for next_word in next_words:\n",
        "        word_probabilities[next_word] = next_words.count(next_word) / word_count\n",
        "\n",
        "    ngram_probabilities[current_word] = word_probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s4e-IjfLIF5w"
      },
      "outputs": [],
      "source": [
        "combined_ngram_probabilities = {}\n",
        "\n",
        "for ngram, next_word_probabilities in ngram_probabilities.items():\n",
        "    combined_key = \" \".join(ngram)  \n",
        "    combined_ngram_probabilities[combined_key] = next_word_probabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hNKugWGQIJk1"
      },
      "outputs": [],
      "source": [
        "def autocomplete(input_text, n=5):\n",
        "    input_text = input_text.lower()\n",
        "\n",
        "    if input_text in combined_ngram_probabilities:\n",
        "        word_probabilities = combined_ngram_probabilities[input_text]\n",
        "        sorted_probabilities = sorted(word_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
        "        suggestions = [word for word, _ in sorted_probabilities[:n]]\n",
        "        return suggestions\n",
        "    else:\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caJ9iTu_l0Gp"
      },
      "source": [
        "# Frontend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NHyQCPwIKvD",
        "outputId": "7d280c7e-9819-4394-d9bd-264a9ebc5d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i was a boy it was a strained silent lunch\n"
          ]
        }
      ],
      "source": [
        "user_input = input(\"Masukkan kata: \")\n",
        "output = user_input\n",
        "\n",
        "for i in range(5):\n",
        "    user_input = user_input.split()\n",
        "    user_input = user_input[-3::]  # Mengambil 3 kata terakhir\n",
        "    user_input = \" \".join(user_input)\n",
        "    suggestions = autocomplete(user_input)\n",
        "    if suggestions:\n",
        "        if isinstance(suggestions[0], tuple):\n",
        "            output += \" \" + \" \".join(suggestions[0])\n",
        "            user_input += \" \" + \" \".join(suggestions[0])\n",
        "        else:\n",
        "            output += \" \" + suggestions[0]\n",
        "            user_input += \" \" + suggestions[0]\n",
        "    else:\n",
        "        user_input = user_input.split()\n",
        "        user_input = user_input[-2::]  # Mengambil 2 kata terakhir\n",
        "        user_input = \" \".join(user_input)\n",
        "        suggestions2 = autocomplete(user_input)\n",
        "        if not suggestions2:\n",
        "            break\n",
        "        output += \" \" + suggestions2[0]\n",
        "        user_input += \" \" + suggestions2[0]\n",
        "\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvMmEIHlRXVt"
      },
      "source": [
        "## Evaluasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLNJMr2lNe6p",
        "outputId": "eb154fca-4104-4c78-e1ca-0a1e6ebf0f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the trigram model: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Buat fungsi evaluasi model trigram\n",
        "def evaluate_trigram_model(sentences, n_grams):\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        words = [word.lower() for word in sentence if word[0].isalpha()]\n",
        "        for ix in range(2, len(words) - 2):  # Sesuaikan indeks sesuai model trigram\n",
        "            current_word = words[ix]\n",
        "            previous_word1 = words[ix - 1]\n",
        "            previous_word2 = words[ix - 2]\n",
        "            next_word = words[ix + 1]\n",
        "            next_word2 = words[ix + 2]\n",
        "            tri_gram = (previous_word2, previous_word1, current_word)\n",
        "\n",
        "            if tri_gram in n_grams:\n",
        "                predictions = n_grams[tri_gram]\n",
        "                if (next_word, next_word2) in predictions:\n",
        "                    correct_predictions += 1\n",
        "                total_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy\n",
        "\n",
        "accuracy = evaluate_trigram_model(sentences, n_grams)\n",
        "print(f\"Accuracy of the trigram model: {accuracy * 100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
